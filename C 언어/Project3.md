## Project3_VIRTUAL MEMORY

### Introduction

#### Background

##### Source Files

- `include/vm/vm.h`, `vm/vm.c`
  - 가상 메모리에 대한 일반 인터페이스를 제공합니다. header file에서 가상 메모리 시스템이 지원해야 하는 다양한 vm_type(VM_UNINT, VM_ANON, VM_FILE, VM_PAGE_CACHE)에 대한 정의와 설명을 볼 수있다(지금은 VM_PAGE_CACHE 무시, 프로젝트 4용임) 여기에서 추가 페이지 테이블도 구현
- `include/vm/uninit.h`, `vm/anon.c`
  - 초기화되지 않은 페이지(vm_type = `VM_UNINIT`)에 대한 작업을 제공합니다. 현재 디자인에서 모든 페이지는 초기에 초기화 되지 않은 페이지로 설정된 다음 anonymous pages, file-backed pages로 변환됩니다.

- `include/vm/anon.h`, `vm/anon.c`
  - 익명 페이지에 대한 작업을 제공(vm_type = `VM_ANON`)
- `include/vm/file.h`, `vm/file.c`
  - 익명 페이지에 대한 작업을 제공(vm_type = `VM_FILE`)



#### Memory Terminology

##### Pages

가상 페이지라고도 하는 페이지는 길이가 4,096바이트(페이지 크기)인 가상 메모리의 연속 영역, 페이지는 페이지 정렬 되어야 합니다. 즉, 페이지 크기로 균등하게 나눌 수 있는 가상 주소에서 시작해야 합니다. 따라서 64비트 가상 주소의 마지막 12비트는 페이지 오프셋입니다. 상위 비트는 곧 소개 될 페이지 테이블의 인덱스를 나타내는데 사용됩니다. 64비트 시스템에서는 가상 주소를 다음과 같이 만드는 4단계 페이지 테이블을 사용합니다.

```c
63          48 47            39 38            30 29            21 20         12 11         0
+-------------+----------------+----------------+----------------+-------------+------------+
| Sign Extend |    Page-Map    | Page-Directory | Page-directory |  Page-Table |    Page    |
|             | Level-4 Offset |    Pointer     |     Offset     |   Offset    |   Offset   |
+-------------+----------------+----------------+----------------+-------------+------------+
              |                |                |                |             |            |
              +------- 9 ------+------- 9 ------+------- 9 ------+----- 9 -----+---- 12 ----+
                                          Virtual Address
```

각 프로세스에는 가상 주소 `KERN_BASE` (0x8004000000) 아래에 있는 페이지인 독립적인 user (virtual) pages 집합이 있습니다. 반면 kernel (virtual) pages 집합은 전역적이므로 실행 중인 thread나 프로세스에 관계없이 동일한 위치에 유지 됩니다. 커널은 user pages와 kernel pages 모두에 엑세스 할 수 있지만 사용자 프로세스는 자신의 사용자 페이지에만 액세스 할 수 있습니다. 

Pintos는 가상 주소 작업을 위한 몇 가지 유용한 기능을 제공합니다. 



##### Frames

물리적 프레임 또는 페이지 프레임 이라고도 하는 프레임은 물리적메모리의 연속 영역입니다. 페이지와 마찬가지로 프레임은 페이지 크기 및 page-aligned 이어야 합니다. 따라서 64비트 물리적 주소는 다음과 같이 프레임 번호와 프레임 오프셋으로 나눌 수 있습니다.

```c
                       12 11         0
    +-----------------------+-----------+
    |      Frame Number     |   Offset  |
    +-----------------------+-----------+
              Physical Address
```

x86-64는 물리적 주소에서 메모리에 직접 액세스하는 방법을 제공하지 않습니다 Pintos는 커널 사상메로리를 물리적 메모리에 직접 매핑하여 이 문제를 해결합니다. 커널 가상 메모리의 첫 번째 페이지는 물리적 메모리의 첫 번째 프레임에 매핑되고 두 번째 페이지는 두 번째 프레임에 매칭 되는 식입니다. 따라서 커널 가상 메모리를 통해 프레임에 액세스 할 수 있습니다.



##### Page Tables

페이지 테이블은 CPU가 가상 주소를 물리적 주소로, 즉 페이지에서 프레임으로 변환하는 데 사용하는 데이터 구조입니다. 페이지 테이블 형식은 x86-64 아키텍처에 의해 결정됩니다. Pintos는 NET에서 페이지 테이블 관리 코드를 제공합니다. `threads/nmu.c`

아래 다이어그램은 페이지와 프레임 간의 관계를 보여줍니다. 왼쪽의 가상 주소는 페이지 번호와 오프셋으로 구성됩니다. 페이지 테이블은 페이지 번호를 수정되지 않은 오프셋과 결합하여 오른쪽의 물리적 주소를 얻는 프레임 번호로 변환합니다.

```c
                     +----------+
         .--------------->|Page Table|-----------.
        /                 +----------+            |
        |   12 11 0                               V  12 11 0
    +---------+----+                         +---------+----+
    | Page Nr | Ofs|                         |Frame Nr | Ofs|
    +---------+----+                         +---------+----+
     Virt Addr   |                            Phys Addr    ^
                  \_______________________________________/
```



##### Swap Slots

swap slots은 swap 파티션에 있는 디스크 공간의 페이지 크기 영역입니다. 슬롯의 배치를 지시하는 하드웨어 제한이 프레임보다 더 유연하지만 스왑 슬롯은 그렇게 하는 데 단점이 없기 때문에 페이지 정렬되어야 합니다.



#### Resource Management Overview



##### Supplemental page table

-  페이지 테이블을 보완하여 페이지 폴트 처리를 가능하게 합니다. 아래의 추가 페이지 테이블 관리를 참조하십시오.

#####  Frame table

- 물리적 프레임의 제거 정책을 효율적으로 구현 할 수 있습니다. 아래의 프레임 테이블 관리를 참조하십시오.

##### Swap table

- 스왑 스롯의 사용을 추적합니다



세 가지 완전히 다른 데이터 구조를 반드시 구현할 필요는 없습니다. 관련 리소스를 전체 또는 부분적으로 통합 데이터 구조로 병합하는 것이 편리 할 수 있습니다. 각 데이터 구족에 대해 각 요소에 포함해야 하는 정보를 결정해야 합니다. 또한 로컬(프로세스별) 또는 전역(전체 시스템에 적용) 중 데이터 구조의 범위와 해당 범위 내에서 필요한 인스턴스 수를 결정해야 합니다. calloc 디자인을 단순화하기 위해 이러한 데이터 구조를 페이징 할 수 없는 메모리(할당 된 메모리  malloc)에 저장 할 수 있습니다. 즉, 그들 사이의 포인터가 유효한 상태로 유지 된다는 것을 확신 한다.



#### Choices of implementation (Performance perspective)

구현을 위한 가능한 선택에는 array, list 비트맵 및 해시 테이블이 포함됩니다. array는 종종 가장 간단한 접근 방식이지만 희소하게 채워진 array는 메모리를 낭비합니다. list 도 간단하지만 특정 위치를 찾기 위해 긴 목록을 탐색하는 것은 시간 낭비입니다. 배열과 목록 모두 크기를 조정할 수 있지만 목록은 중간에 삽입 삭제를 더 효율적으로 지원합니다.

`lib/kernel/bitma.c` Pintos는 비트맵 데이터 구조를 포함 합니다. ` include/lib/kernel/bitmap.h` 비트맵은 각각 참 또는 거짓이 될 수 있는 비트의 배열입니다. 비트맵은 일반적으로 (동일한) 리소스 집합에서 사용량을 추적하는데 사용됩니다. 리소스 n이 사용 중인 경우 비트맵의 비트 n이 참입니다. Pintos 비트맵은 크기가 고정되어 있지만 크기 조정을 지원하도록 구현을 확장

Pintos는 또한 해시 테이블 구조를 포함합니다.  Pintos 해시 테이블은 다양한 테이블 그기에서 삽입 및 삭제를 효율적으로 지원합니다.



#### Managing the Supplemental Page Table

추가 페이지 테이블은 각 페이지에 대한 추가 데이터로 페이지 테이블을 보완합니다. 페이지 테이블의 형식에 따른 제한 때문에 필요합니다. 이러한 데이터 구조는 종종 "page Table"이라고도 합니다. 혼동을 줄이기 위해 "Supplemental"이라는 단어를 추가합니다.

Supplemental page Table은 적어도 두가지 용도로 사용됩니다. 

1. 가장 중요한 것은 페이지 폴트 시 커널이 추가 페이지 테이블에서 폴트가 발생한 가상 페이지를 조회하여 어떤 데이터가 있어야 하는지 알아내는 것입니다. 
2. 커널은 프로세스가 종료 될 때, 추가 페이지 테이블을 참조하여 해제할 리소스를 결정합니다.



##### Organization of Supplemental Page Table

원하는 대로 추가 페이지 테이블을 구성 할 수 있습니다. 구성에는 세그먼트 또는 페이지 측면에서 최소한 두가지 접근 방식이 있습니다. 여기서 세그먼트는 페이 그룹, 즉 실행 파일 또는 메모리 매핑 파일을 포함하는 메모리 영역을 나타냅니다.

선택적으로 페이지 테이블 자체를 사용하여 추가 페이지 테이블의 구성원을 추적 할 수 있습니다. `threads/mmu.c` 그렇게 하려면  Pintos 페이지 테이블 구현을 수정해야 합니다. 



##### Handling page fault

보조 페이지 테이블의 가장 중요한 사용자는 페이지 오류 처리기 입니다. project 2에서 페이지 오류는 항상 커널 또는 사용자 프로그램의 버그를 나타냅니다. Project3 에서는 더 이상 그렇지 않습니다. 이제 페이지 오류는 파일 또는 스왑 슬롯에서 페이지를 가져와야 한다는 것을 나타낼 수 있습니다. 이러한 경우를 처리 할려면 보다 정교한 페이지 폴트 처리기를 구현 해야 합니다. `page_fault()` 에 있는 페이지 폴트 핸들러는 `userprog/exception.c` 에 있는 페이지 폴트 핸들러를 호출 합니다.  페이지 오류 처리기는 대략 다음을 수행해야 합니다. `wm_try_handle_fault() vm/vm.c` 

1. 보충 페이지 테이블에서 오류가 발생한 페이지를 찾습니다. 메모리 참조가 유효한 경우 추가 페이지 테이블 항목을 사용하여 파일 시스템 또는 스왑 슬롯에 있을 수 있는 페이지에 들어가는 데이터를 찾거나 단순히 모두 0인 페이지 일 수 있습니다. 공유(즉, copy-on-write)를 구현하면 페이지의 데이터가 이미 페이지 프레임에는 있지만 페이지 테이블에는 없을 수 도 있습니다. 추가 페이지 테이블이 사용자 프로세스나 액세스 하려는 주소에서 데이터를 기대해서는 안 된다고 표시하는 경우. 페이지가 커널 가상 메모리내에 있는 경우, 액세스가 일기 전용 페이지에 쓰려는 시도인 경우 그러면 액세스가 유효 하지 않습니다. 유효하지 않는 액세스는 프로세스를 종료하여 모든 리소스를 해제 합니다.
2. 페이지를 저장할 프레임을 얻습니다. 공유를 구현하는 경우 필요한 데이터가 이미 프레임에 있을 수 있으며 이 경우 해달 프레임을 찾을 수 있어야 합니다
3. 파일 시스템 또는 스왑, 제로화 등에서 데이터를 읽어 프레임으로 가져옵니다. 공유를 구현하는 경우 필요한 페이지가 이미 프레임에 있을 수 있으며 이 경우 이 단계에서 조치가 필요하지 않습니다.
4. 결함이 있는 가상 주소에 대한 페이지 테이블 항목이 물리적 페이지를 가리키도록 합니다. 



#### Managing the Frame Table

프레임 테이블은 각 프레임에 대해 하나의 항목을 포함합니다. 프레임 테이블의 각 항목에는 현재 이를 차지하고 있는 페이지에 대한 포인터(있는 경우)와 선택한 기타 데이터가 포합 됩니다.  프레임 테이블을 사용하면 빈 프레임이 없을 때 제거할 페이지를 선택하여 Pintos가 제거 정책을 효율적으로 구현 할 수 있습니다.

사용자 페이지에 사용되는 프레임은 palloc_get_page(PAL_USER)를 호출하여 "user pool"에서 얻어야 합니다. 이러한 경우, "kernel pool"에서 할당하는 것을 피해야 하며, 그렇지 않으면 일부 테스트 케이스가 예기치 않게 실패할 수 있습니다. 프레임 테이블 구현의 일환으로 palloc.c를 수정하는 경우, 두 개의 pool 간 구분을 유지해야 함을 기억해야 합니다.

프레임 테이블에서 가장 중요한 작업은 사용하지 않은 프레임을 얻는 것입니다. 프레임이 비어 있으면 쉽습니다. 사용 가능한 것이 없으면 프레임에서 일부 페이지를 제거하여 프레임을 사용 가능하게 만들어야 합니다.

스왑슬롯을 할당하지 않고 프레임을 제거할 수 없지만 스왑이 가득 커널을 패닉 상태로 만듭니다. 실제 OS는 이러한 상황을 복구하거나 방지하기 위해 광범위한 정책을 적용하지만 이러한 정책은 이 프로젝트 범위를 벗어납니다.

퇴거 절차는 대략 다음 단계로 구성됩니다.

1. 페이지 교체 알고리즘을 사용하여 축출할 프레임을 선택하십시오. 아래에 설명된 페이지 테이블의 "액세스된" 및 "더티" 비트가 유용합니다.
2. 프레임을 참조하는 모든 페잊 테이블에서 프레임에 대한 참조를 제거합니다. 공유를 구현하지 않는 경우 단일 페이지만 주어진 시간에 프레임을 참조해야 합니다.
3. 필요한 경우 페이지를 파일 시스템에 쓰거나 스왑합니다. 제거된 프레임은 다른 페이지를 저장하는 데 사용 될 수 있습니다.



#### Accessed and Dirty Bits

x86-64 하드웨어는 각 페이지에 대한 페이지 테이블 항목(PTE)의 비트 쌍을 통해 페이지 교체 알고리즘을 구현하기 위한 일부 지원을 제공합니다. 페이지에 대한 모든 읽기 또는 쓰기에서 CPU는 페이지의 PTE에서 액세스된 비트를 1로 설정하고 모든 쓰기에서 CPU는 더티 비트를 1로 설정합니다. CPU는 이러한 비트를 0으로 재설정하지 않지만 OS는 다음을 수행 할 수 있습니다. 

그래서 `aliases` 즉, 동일한 프레임을 참조하는 두 페이지(또는 그 이상)를 알아야 합니다. 앨리어싱된 프레임에 액세스하면 액세스된 비트와 더티 비트는 하나의 페이지 테이블 항목(액세스에 사용된 페이지에 대한 항목)에 서만 업데이트됩니다. 다른 별칭에 대한 액세스 및 더티 비트는 업데이트 되지 않습니다.

 Pintos에서 모든 사용자 가상 페이지는 커널 가상 페이지에 별칭이 지정됩니다. 어떻게든 이러한 별칭을 관리해야 합니다. 예를 들어 코드는 두 주소 모두에 대해 액세스된 비트와 더티 비트를 확인하고 업데이트 할 수 있습니다. 또는 커널이 사용자 가상 주소를 통해서만 사용자 데이터에 액세스하면 문제를 피할 수 있습니다.



#### Managing the Swap Table

스왑 테이블은 사용 중인 스왑 슬롯과 빈 스왑 슬롯을 추적합니다. 스왑 슬롯을 선택하여 해당 프레임에서 페이지를 스왑 파티션으로 대체하는 데 사용되며, 페이지가 다시 읽혀지거나 해당 페이지가 스왑된 프로세스가 종료될 때 스왑 슬롯을 해제할 수 있어야 합니다.

vm/build 디렉토리에서 'pintos-mkdisk swap.dsk --swap-size=n' 명령을 사용하여 n-MB 스왑 파티션을 포함하는 swap.dsk라는 디스크를 생성하십시오. 그 후, swap.dsk는 pintos를 실행할 때 자동으로 추가 디스크로 연결됩니다. 또는 단일 실행에 대해 임시 n-MB 스왑 디스크를 사용하도록 pintos에 알려줄 수도 있습니다. --swap-size=n을 사용하세요.

스왑 슬롯은 게으르게 할당되어야 합니다. 즉, 실제로 페이지 대체에 필요할 때만 할당되어야 합니다. 실행 가능한 데이터 페이지를 프로세스 시작 시 즉시 읽어서 스왑에 기록하는 것은 게으르지 않습니다. 스왑 슬롯은 특정 페이지를 저장하기 위해 예약되어서는 안 됩니다.

콘텐츠가 프레임으로 다시 읽혀진 경우 스왑 슬롯을 해제하십시오.



### QnA

Q1. 실제로는 그렇지 않지만 Pintos 에서는 유저 가상 메모리의 모든 페이지가 커널 가상 메모리에도 존재한다는 뜻인가요??



A1. PintOS에서 physical memory는 전부 kernel virtual address space에 mapping되고, ptov, vtop 매크로등을 이용하여 physical address <-> kernel virtual address 간의 변환을 수행하게 됩니다.

이때, paging에 의해 user virtual address에 physical memory frame이 mapping이 생성되면 다음과 같이 두개의 virtual -> physical address mapping이 page table상에 존재 하게 되는데, 이를 aliases라고 표현하고 있습니다. 

```c
user_VA --------> PA
             /
kernel_VA----
```

따라서 PA에 발생하는 접근은 user process가 user_VA를 사용하거나, OS가 user_VA또는 kernel_VA를 사용하여 수행 될 수 있으나, CPU는 두 virtual address 중 실제 접근에 사용된 address의 pte에만 accessed/dirty bit를 mark 하므로 동일한 physical memory를 가르키는 두 pte 간의 차이가 발생하게 됩니다.

Document에서는 이러한  aliases를 해결하기 위해 두가지 접근법을 제시하고 있습니다. -user_VA 또는 kernel_VA를 통해 PA에 접근 할 시 다른 한쪽의  pte를 같이  check하고 update하는 방식과, OS가 user process에게 mapping해준  PA에 접근할 시 무조건 user_VA만을 사용하는 방식입니다.

A2. 위에서 계산한 모든 크기는 virtual address space의 크기이며, 해당 크기 만큼의 physical memory가 해당 address space에 mapping 될 수 있음을 의미합니다.  즉, 계산된  virtual address space의 크기는 해당영역에 mapping될 수 있는 physical memory의 최대 크기라고 생각하시면 된다. (이는 32bit cpu와 os 상에서 4GB 이상의 RAM을 사용하지 못하는 이유) 아래 그림을 통해 user/kernel virtual address space와 physical memory간의  mapping이 어떻게 이루어지는지 살펴 보실 수 있습니다. 

Q2. 유저프로그램 실행 후 lazy_load_segment()가 실행되는 순서가 궁금하여 질문 드립니다.

load_segment에서 uninit으로 유저페이지를 400000, 401000, 402000, 403000, 404000, 604000, 605000 할당 하였습니다. 유저 프로그램이 400000을 요청하여서 다음에서는 401000을 요청할 줄 알았지만 (첫 pageFault 요청) 이후 605000을 요청하였습니다. 유저 프로그램의 행동방식을 어떻게 알 수 있을까요??



A2. 한 프로세스 내에서 page fault가 일어나는 행동양상은 page fault가 일어나는 순서를 관찰하면 파악 할 수 있습니다. 실제 운영체제에서는 스택의 위치가 프로그램을 켤 때마다 조금씩 바뀐다던가 하는 차이가 있지만 pintos에서는 그런 작업은 하지 않으므로 동일한 프로그램은 같은 순서로 page fault가 일어날 것입니다.

물론 fork()를 통해 여러 가지 프로세스가 실행되면 여러 개의 프로세스에서 동시에 page fault가 일어날 것이고, 이 때는 scheduling의 방식에 따라 미묘하게 page fault가 일어나는 양상이 달라지며, 일어나는 순서는 정해진 순서가 없기 때문에 이 경우에는 행동방식을 파악하기 어렵습니다.



Q3. load_segment로 파일을 읽을때는 파일전체를 읽는게 아닌가요??

USERPROG의 첫번째 테스트(agrs-none)의 경우 file_length로 찍어본 파일 안의 비트는 51,312 이지만  load_segment에서 읽는 총 read_byte는 19738이고 zero_byte는 742라서 합이 20480으로 차이가 있습니다 load_segment에서 읽어 보는 정보는 어떤 정보인가요??

load_segment에서 마지막에 read_byte는 0이고 zero_byte가 4096인 페이지를 두번 읽는데, 이 페이지의 용도는 무엇인가요??  lazy_load_segment에서 zero_byte 부분에 memset으로 0을 채워주는데, page_fault로 연결되어 무한 루프에 빠지고 있습니다.

데이터를 읽는 것은 프로세서의 code 영역이고 zero_byte로 이루어진 두 페이지는 스택과 힙 영역으로 생각되는데 맞나요??



A3. 응용 프로그램들은 ELF format에 맞게 저장되어 있으므로 pintos의 load() 에서는 ELF format을 적절하게 읽어옵니다. ELF format을 보면 ELF header 나 .debug와 같은 메모리에 로드되지 않지만 ELF에는 존재하는 영역이 있습니다. 이런 부분은 load_segment를 통해 메모리를 할당하지 않을 것이고, 또한 .bss와 같은 uninitizlized segment같은 경우는 파일에 세그먼트 헤더만 있지 내용은 없지만 메모리는 할당해 줍니다. 그러므로 단순히 응용프로그램의 크기와 load_segment에서 읽은 용량은 같지 않을 수 있습니다.  zero_byte로 이루어진 페이지는 스택과 힙 영역이라고 보기는 어렵습니다. 우선 pintos에서 스택영역은 setup_stack() 함수를 통해 직접 할당해줍니다. 힙 영역도 user program이 malloc을 통해 메모리를 할당할 때마다 필요에 따라 메모리를 할당하므로, 스택 영역과 마찬가지로 elf 파일로 부터 읽어오는 정보는 아닙니다. 다만 zero_byte 만으로 이루어진 페이지들로 가능한 후보를 생각하면 .bss 영역에 들어가는 정보가 생각나네요. uninitialized global variable이나 uninitialized static varible 등이 이 영역에 들어가며, 초기값이 중요하지 않으므로 elf 파일에는 값이 지정되어 있지 않으나 메모리 할당은 해줘야 하므로 zero_byte = 4096으로 할당이 될 것입니다.

 
